# -*- coding: utf-8 -*-
"""mental_health_ui.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NmsW3TLqh3p_YozlRhbold7HEpP6L20A
"""

import os
!pip install -q kaggle

# Check if kaggle.json exists
if os.path.exists("/root/.kaggle/kaggle(1).json"):
    print("kaggle.json already exists!")
else:
    print("Upload kaggle.json and move it to /root/.kaggle/")

# Verify Kaggle authentication by listing datasets
!kaggle datasets list | head -n 10

import os
import shutil

# Create .kaggle directory if it doesn't exist
os.makedirs("/root/.kaggle", exist_ok=True)

# Move kaggle.json to the correct directory
shutil.move("/content/kaggle.json", "/root/.kaggle/kaggle.json")

# Set permissions to secure the file
os.chmod("/root/.kaggle/kaggle.json", 600)

# Verify by listing datasets
!kaggle datasets list | head -n 10

!kaggle datasets list -s depression

!pip install -q kaggle

# Verify Kaggle authentication
!kaggle datasets list | head -n 10

!kaggle datasets download -d shahzadahmad0402/depression-and-anxiety-data

import zipfile

# Unzip the downloaded file
!unzip -q depression-and-anxiety-data.zip

import os

# List all files in the current directory
os.listdir()

import pandas as pd

# Replace 'your_file.csv' with the actual CSV filename
df = pd.read_csv("depression_anxiety_data.csv")

# Display first 5 rows
df.head()

# Get dataset information
df.info()

# Check missing values
df.isnull().sum()

# Fill missing categorical values with mode
categorical_cols = ['depression_severity', 'depressiveness', 'suicidal',
                    'depression_diagnosis', 'depression_treatment', 'anxiousness',
                    'anxiety_diagnosis', 'anxiety_treatment', 'sleepiness']

for col in categorical_cols:
    df[col].fillna(df[col].mode()[0], inplace=True)

# Fill missing categorical values with mode
categorical_cols = ['depression_severity', 'depressiveness', 'suicidal',
                    'depression_diagnosis', 'depression_treatment', 'anxiousness',
                    'anxiety_diagnosis', 'anxiety_treatment', 'sleepiness']

df[categorical_cols] = df[categorical_cols].apply(lambda x: x.fillna(x.mode()[0]))

# Fill missing numerical values with median
numerical_cols = ['epworth_score']
df[numerical_cols] = df[numerical_cols].apply(lambda x: x.fillna(x.median()))

# Check if any missing values remain
print(df.isnull().sum())

# Normalize text columns: convert to lowercase and strip spaces
text_cols = ['gender', 'who_bmi', 'depression_severity', 'depressiveness',
             'suicidal', 'depression_diagnosis', 'depression_treatment',
             'anxiety_severity', 'anxiousness', 'anxiety_diagnosis',
             'anxiety_treatment', 'sleepiness']

df[text_cols] = df[text_cols].apply(lambda x: x.str.lower().str.strip())

# Convert non-string values to string and fill NaN values with 'unknown'
df[text_cols] = df[text_cols].apply(lambda x: x.fillna('unknown').astype(str).str.lower().str.strip())

# Check unique values for categorical columns
for col in text_cols:
    print(f"{col}: {df[col].unique()}")

# Binary encoding for boolean columns
boolean_cols = ['depressiveness', 'suicidal', 'depression_diagnosis',
                'depression_treatment', 'anxiousness', 'anxiety_diagnosis',
                'anxiety_treatment', 'sleepiness']

df[boolean_cols] = df[boolean_cols].apply(lambda x: x.map({'false': 0, 'true': 1}))

# Mapping ordinal columns to integers based on severity
bmi_mapping = {
    'underweight': 1,
    'normal': 2,
    'overweight': 3,
    'class i obesity': 4,
    'class ii obesity': 5,
    'class iii obesity': 6,
    'not availble': 0  # Treat 'not available' as 0
}

severity_mapping = {
    'none-minimal': 0,
    'mild': 1,
    'moderate': 2,
    'moderately severe': 3,
    'severe': 4
}

# Apply the mappings
df['who_bmi'] = df['who_bmi'].map(bmi_mapping)
df['depression_severity'] = df['depression_severity'].map(severity_mapping)
df['anxiety_severity'] = df['anxiety_severity'].map(severity_mapping)

# Correlation matrix for numerical features
import seaborn as sns
import matplotlib.pyplot as plt

# Select numerical columns for correlation matrix
numerical_cols = ['age', 'bmi', 'phq_score', 'gad_score', 'epworth_score']

# Calculate correlation matrix
correlation_matrix = df[numerical_cols].corr()

# Plot heatmap of correlations
plt.figure(figsize=(10, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Matrix")
plt.show()

from sklearn.feature_selection import chi2
from sklearn.preprocessing import LabelEncoder

# Convert categorical target column to numeric (0/1 for binary classification)
label_encoder = LabelEncoder()
df['depression_diagnosis'] = label_encoder.fit_transform(df['depression_diagnosis'])

# Convert categorical features into numeric using LabelEncoder
categorical_cols = ['gender', 'who_bmi', 'depression_severity', 'depressiveness',
                    'suicidal', 'depression_treatment', 'anxiety_severity',
                    'anxiousness', 'anxiety_diagnosis', 'anxiety_treatment', 'sleepiness']

for col in categorical_cols:
    df[col] = label_encoder.fit_transform(df[col])

# Create feature matrix X and target vector y
X = df[categorical_cols]
y = df['depression_diagnosis']

# Apply chi-square test
chi2_values, p_values = chi2(X, y)

# Display results
chi2_results = pd.DataFrame({
    'Feature': categorical_cols,
    'Chi2 Value': chi2_values,
    'P Value': p_values
})

print(chi2_results)

import matplotlib.pyplot as plt
import seaborn as sns

# 1. Summary Statistics for Numerical Data
print("Summary Statistics for Numerical Columns")
print(df.describe())

# 2. Distribution of Numerical Columns (e.g., age, BMI, scores)
numerical_cols = ['age', 'bmi', 'phq_score', 'gad_score', 'epworth_score']
plt.figure(figsize=(15, 10))
for i, col in enumerate(numerical_cols, 1):
    plt.subplot(2, 3, i)
    sns.histplot(df[col], kde=True)
    plt.title(f'{col} Distribution')
plt.tight_layout()
plt.show()

# 3. Distribution of Categorical Data using Bar Plots
categorical_cols = ['gender', 'who_bmi', 'depression_severity', 'depressiveness',
                    'suicidal', 'depression_treatment', 'anxiety_severity',
                    'anxiousness', 'anxiety_diagnosis', 'anxiety_treatment', 'sleepiness']

plt.figure(figsize=(15, 12))
for i, col in enumerate(categorical_cols, 1):
    plt.subplot(3, 4, i)
    sns.countplot(x=df[col])
    plt.title(f'{col} Count Plot')
    plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# 4. Correlation Heatmap for Numerical Features
correlation_matrix = df[numerical_cols].corr()
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title("Correlation Heatmap for Numerical Features")
plt.show()

# 5. Pairplot for Numerical Features (for relationship analysis)
sns.pairplot(df[numerical_cols])
plt.suptitle("Pairwise Relationships Between Numerical Features", y=1.02)
plt.show()

# 6. Investigating Relationships Between Features (Depression Diagnosis vs. Other Features)
plt.figure(figsize=(15, 8))
sns.countplot(x='depression_diagnosis', hue='gender', data=df)
plt.title('Depression Diagnosis vs Gender')
plt.show()

# Visualize relationship between depression severity and other features
plt.figure(figsize=(15, 8))
sns.countplot(x='depression_severity', hue='anxiety_severity', data=df)
plt.title('Depression Severity vs Anxiety Severity')
plt.show()

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# Load dataset
df = pd.read_csv("depression_anxiety_data.csv")

# Encode categorical features
categorical_cols = ['gender', 'who_bmi', 'depression_severity', 'depressiveness',
                    'suicidal', 'depression_treatment', 'anxiety_severity',
                    'anxiousness', 'anxiety_diagnosis', 'anxiety_treatment', 'sleepiness']

label_encoders = {}
for col in categorical_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le  # Store encoders for later use

# Define target variable
target = 'depression_diagnosis'  # You can change this to another mental health condition
df[target] = LabelEncoder().fit_transform(df[target])

# Split dataset
X = df.drop(columns=['id', target])
y = df[target]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score

# Train Random Forest Model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
rf_preds = rf_model.predict(X_test)

# Train XGBoost Model
xgb_model = XGBClassifier(use_label_encoder=False, eval_metric="mlogloss", random_state=42)
xgb_model.fit(X_train, y_train)
xgb_preds = xgb_model.predict(X_test)

# Evaluate Models
print("Random Forest Results:")
print(classification_report(y_test, rf_preds))
print("ROC-AUC:", roc_auc_score(y_test, rf_model.predict_proba(X_test), multi_class='ovr'))

print("\nXGBoost Results:")
print(classification_report(y_test, xgb_preds))
print("ROC-AUC:", roc_auc_score(y_test, xgb_model.predict_proba(X_test), multi_class='ovr'))

from sklearn.preprocessing import label_binarize

# Binarize the labels for multi-class ROC-AUC calculation
y_test_binarized = label_binarize(y_test, classes=np.unique(y_train))

# Evaluate Models
print("Random Forest Results:")
print(classification_report(y_test, rf_preds))
print("ROC-AUC:", roc_auc_score(y_test_binarized, rf_model.predict_proba(X_test), multi_class='ovr'))

print("\nXGBoost Results:")
print(classification_report(y_test, xgb_preds))
print("ROC-AUC:", roc_auc_score(y_test_binarized, xgb_model.predict_proba(X_test), multi_class='ovr'))

print("Shape of y:", y.shape)

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score

# Load dataset (replace with your actual dataset)
# X, y = ...

# Check the shape of y
print("Shape of y:", y.shape)

# Split the data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Ensure y_train and y_test are 1D
print("Shape of y_train:", y_train.shape)
print("Shape of y_test:", y_test.shape)

# Train Random Forest Model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
rf_preds = rf_model.predict(X_test)

# Train XGBoost Model
xgb_model = XGBClassifier(use_label_encoder=False, eval_metric="mlogloss", random_state=42)
xgb_model.fit(X_train, y_train)
xgb_preds = xgb_model.predict(X_test)

# Ensure predictions are 1D
rf_preds = np.squeeze(rf_preds)
xgb_preds = np.squeeze(xgb_preds)

# Evaluate Models
print("Random Forest Results:")
print(classification_report(y_test, rf_preds))
print("ROC-AUC:", roc_auc_score(y_test, rf_model.predict_proba(X_test), multi_class='ovr'))

print("\nXGBoost Results:")
print(classification_report(y_test, xgb_preds))
print("ROC-AUC:", roc_auc_score(y_test, xgb_model.predict_proba(X_test), multi_class='ovr'))

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score

# Load dataset (replace with your actual dataset)
# X, y = ...

# Check the shape of y
print("Shape of y:", y.shape)

# Split the data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Ensure y_train and y_test are 1D
print("Shape of y_train:", y_train.shape)
print("Shape of y_test:", y_test.shape)

# Train Random Forest Model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
rf_preds = rf_model.predict(X_test)

# Train XGBoost Model
xgb_model = XGBClassifier(use_label_encoder=False, eval_metric="mlogloss", random_state=42)
xgb_model.fit(X_train, y_train)
xgb_preds = xgb_model.predict(X_test)

# Ensure predictions are 1D
rf_preds = np.squeeze(rf_preds)
xgb_preds = np.squeeze(xgb_preds)

# Evaluate Models
print("Random Forest Results:")
print(classification_report(y_test, rf_preds))

# Ensure y_test is 1D
if len(y_test.shape) > 1:
    y_test = np.squeeze(y_test)

# Calculate ROC-AUC for Random Forest
rf_probs = rf_model.predict_proba(X_test)
rf_roc_auc = roc_auc_score(y_test, rf_probs, multi_class='ovr')
print("Random Forest ROC-AUC:", rf_roc_auc)

print("\nXGBoost Results:")
print(classification_report(y_test, xgb_preds))

# Calculate ROC-AUC for XGBoost
xgb_probs = xgb_model.predict_proba(X_test)
xgb_roc_auc = roc_auc_score(y_test, xgb_probs, multi_class='ovr')
print("XGBoost ROC-AUC:", xgb_roc_auc)

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score

# Load dataset (replace with your actual dataset)
# X, y = ...

# Check the shape of y before splitting
print("Shape of y before splitting:", y.shape)

# Convert one-hot encoded labels to 1D array if necessary
if len(y.shape) > 1 and y.shape[1] > 1:
    y = np.argmax(y, axis=1)  # Convert to 1D array
    print("Shape of y after conversion:", y.shape)

# Split the data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Debugging: Check shapes after splitting
print("Shape of y_train after splitting:", y_train.shape)
print("Shape of y_test after splitting:", y_test.shape)

# Train Random Forest Model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
rf_preds = rf_model.predict(X_test)

# Train XGBoost Model
xgb_model = XGBClassifier(use_label_encoder=False, eval_metric="mlogloss", random_state=42)
xgb_model.fit(X_train, y_train)
xgb_preds = xgb_model.predict(X_test)

# Ensure predictions are 1D
rf_preds = np.squeeze(rf_preds)
xgb_preds = np.squeeze(xgb_preds)

# Evaluate Models
print("Random Forest Results:")
print(classification_report(y_test, rf_preds))

# Ensure y_test is 1D
if len(y_test.shape) > 1:
    y_test = np.squeeze(y_test)

# Calculate ROC-AUC for Random Forest
rf_probs = rf_model.predict_proba(X_test)
rf_roc_auc = roc_auc_score(y_test, rf_probs, multi_class='ovr')
print("Random Forest ROC-AUC:", rf_roc_auc)

print("\nXGBoost Results:")
print(classification_report(y_test, xgb_preds))

# Calculate ROC-AUC for XGBoost
xgb_probs = xgb_model.predict_proba(X_test)
xgb_roc_auc = roc_auc_score(y_test, xgb_probs, multi_class='ovr')
print("XGBoost ROC-AUC:", xgb_roc_auc)

pip install shap

import shap

# Create SHAP Explainer
explainer = shap.TreeExplainer(rf_model)
shap_values = explainer.shap_values(X_test)

# Plot Summary
shap.summary_plot(shap_values, X_test)

import joblib

# Save the model
joblib.dump(rf_model, "mental_health_rf_model.pkl")

import joblib
import numpy as np
import pandas as pd

# Load the trained model
model = joblib.load("mental_health_rf_model.pkl")

def predict_mental_health(symptoms):
    """
    Predict mental health condition based on input symptoms.

    Args:
        symptoms (list): A list of symptom values corresponding to model features.

    Returns:
        int: Predicted mental health condition (e.g., 0 = No diagnosis, 1 = Depression).
    """
    # Convert input to numpy array and reshape for model
    symptoms_array = np.array(symptoms).reshape(1, -1)

    # Make prediction
    prediction = model.predict(symptoms_array)

    return int(prediction[0])  # Convert numpy int to Python int

if __name__ == "__main__":
    # Example input (adjust according to your dataset's feature format)
    example_input = [0.5, 1, 3, 2, 0, 1]  # Replace with real feature values
    result = predict_mental_health(example_input)
    print(f"Predicted Mental Health Condition: {result}")

print(f"Training feature shape: {X_train.shape}")  # Should print (rows, 17)

def predict_mental_health(symptoms):
    if len(symptoms) != 17:
        raise ValueError(f"Expected 17 features, but got {len(symptoms)}")

    symptoms_array = np.array(symptoms).reshape(1, -1)
    prediction = model.predict(symptoms_array)

    return int(prediction[0])

print(f"Model was trained on {rf_model.n_features_in_} features.")

import numpy as np
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score
from sklearn.model_selection import train_test_split

# Ensure y is 1D and merge rare class (if applicable)
y = np.ravel(y)  # Flatten the target variable if it's a 2D array

y = np.where(y == 2, 1, y)  # Convert class 2 → class 1

# Train-Test Split with Stratification
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"Training feature shape: {X_train.shape}")  # Ensure X_train has the correct feature count

# ✅ Train Random Forest Model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
rf_preds = rf_model.predict(X_test)
rf_probs = rf_model.predict_proba(X_test)

# ✅ Train XGBoost Model
xgb_model = XGBClassifier(use_label_encoder=False, eval_metric="mlogloss", random_state=42)
xgb_model.fit(X_train, y_train)
xgb_preds = xgb_model.predict(X_test)
xgb_probs = xgb_model.predict_proba(X_test)

# ✅ Evaluate Models
print("Random Forest Results:")
print(classification_report(y_test, rf_preds))
if len(np.unique(y_test)) > 1:
    print("ROC-AUC:", roc_auc_score(y_test, rf_probs[:, 1]))  # Fix: Ensure more than one class exists

print("\nXGBoost Results:")
print(classification_report(y_test, xgb_preds))
if len(np.unique(y_test)) > 1:
    print("ROC-AUC:", roc_auc_score(y_test, xgb_probs[:, 1]))  # Fix: Ensure more than one class exists

import joblib

# Save the trained Random Forest model
joblib.dump(rf_model, 'rf_model.pkl')

# Save the trained XGBoost model
joblib.dump(xgb_model, 'xgb_model.pkl')

import shap

# SHAP for Random Forest Model
explainer_rf = shap.TreeExplainer(rf_model)
shap_values_rf = explainer_rf.shap_values(X_test)

# SHAP for XGBoost Model
explainer_xgb = shap.TreeExplainer(xgb_model)
shap_values_xgb = explainer_xgb.shap_values(X_test)

# Visualizing SHAP summary for Random Forest Model
shap.summary_plot(shap_values_rf, X_test)

# Visualizing SHAP summary for XGBoost Model
shap.summary_plot(shap_values_xgb, X_test)

import pandas as pd
import joblib

# Load the trained Random Forest model
rf_model = joblib.load('rf_model.pkl')

def predict_mental_health(symptom_data):
    """
    Function to predict mental health diagnosis based on symptom data.
    :param symptom_data: pandas DataFrame, should match the features used during training.
    :return: predicted class
    """
    # Ensure symptom_data is in the correct format (it must be a DataFrame)
    prediction = rf_model.predict(symptom_data)  # Or use xgb_model.predict(symptom_data)
    return prediction

# Example usage:
# Prepare some sample new data with the correct features
new_data = pd.DataFrame({
    'age': [30],  # Example: Age of the person
    'school_year': [2],  # Example: School year (1-12)
    'gender': [1],  # Example: 1 for male, 0 for female (or other encoding)
    'bmi': [23],  # Example: BMI value
    'who_bmi': ['Normal'],  # Example: WHO BMI classification ('Normal', 'Overweight', etc.)
    'phq_score': [12],  # Example: PHQ score (for depression screening)
    'depression_severity': [2],  # Example: Depression severity (1-5 scale)
    'depressiveness': [3],  # Example: Level of depressiveness (1-5 scale)
    'suicidal': [1],  # Example: 1 for suicidal thoughts, 0 for no
    'depression_treatment': [1],  # Example: 1 for treatment, 0 for no treatment
    'gad_score': [10],  # Example: GAD score (for anxiety)
    'anxiety_severity': [3],  # Example: Anxiety severity (1-5 scale)
    'anxiousness': [4],  # Example: Level of anxiousness (1-5 scale)
    'anxiety_diagnosis': [1],  # Example: 1 for diagnosed with anxiety, 0 for not
    'anxiety_treatment': [1],  # Example: 1 for treatment, 0 for no treatment
    'epworth_score': [9],  # Example: Epworth score for sleepiness
    'sleepiness': [3],  # Example: Sleepiness level (1-5 scale)
})
# Make the prediction
prediction = predict_mental_health(new_data)
print(f"Predicted mental health diagnosis: {prediction}")

# Assuming X_train is your training data
print(X_train.columns)

# Assuming you have used RandomForestClassifier
# Get the feature order from the trained model
feature_order = X_train.columns  # X_train is the training dataset

# Now ensure new_data has columns in the same order
new_data = new_data[feature_order]

import pandas as pd
import joblib

# Load the trained Random Forest model
rf_model = joblib.load('rf_model.pkl')

def predict_mental_health(symptom_data):
    """
    Function to predict mental health diagnosis based on symptom data.
    :param symptom_data: pandas DataFrame, should match the features used during training.
    :return: predicted class
    """
    # Ensure symptom_data is in the correct format (it must be a DataFrame)
    prediction = rf_model.predict(symptom_data)  # Or use xgb_model.predict(symptom_data)
    return prediction

# Example usage:
# Prepare some sample new data with the correct features
new_data = pd.DataFrame({
    'age': [30],  # Example: Age of the person
    'school_year': [2],  # Example: School year (1-12)
    'gender': [1],  # Example: 1 for male, 0 for female (or other encoding)
    'bmi': [23],  # Example: BMI value
    'who_bmi': ['Normal'],  # Example: WHO BMI classification ('Normal', 'Overweight', etc.)
    'phq_score': [12],  # Example: PHQ score (for depression screening)
    'depression_severity': [2],  # Example: Depression severity (1-5 scale)
    'depressiveness': [3],  # Example: Level of depressiveness (1-5 scale)
    'suicidal': [1],  # Example: 1 for suicidal thoughts, 0 for no
    'depression_treatment': [1],  # Example: 1 for treatment, 0 for no treatment
    'gad_score': [10],  # Example: GAD score (for anxiety)
    'anxiety_severity': [3],  # Example: Anxiety severity (1-5 scale)
    'anxiousness': [4],  # Example: Level of anxiousness (1-5 scale)
    'anxiety_diagnosis': [1],  # Example: 1 for diagnosed with anxiety, 0 for not
    'anxiety_treatment': [1],  # Example: 1 for treatment, 0 for no treatment
    'epworth_score': [9],  # Example: Epworth score for sleepiness
    'sleepiness': [3],  # Example: Sleepiness level (1-5 scale)
})
# Make the prediction
prediction = predict_mental_health(new_data)
print(f"Predicted mental health diagnosis: {prediction}")

import pandas as pd
import joblib

# Load the trained Random Forest model
rf_model = joblib.load('rf_model.pkl')

# Define the exact feature order used during training
feature_order = [
    'school_year', 'age', 'gender', 'bmi', 'who_bmi', 'phq_score',
    'depression_severity', 'depressiveness', 'suicidal', 'depression_treatment',
    'gad_score', 'anxiety_severity', 'anxiousness', 'anxiety_diagnosis',
    'anxiety_treatment', 'epworth_score', 'sleepiness'
]

# Example of new symptom data (ensure the data has the same features in the same order)
new_data = pd.DataFrame({
    'school_year': [2],  # Example: Year in school
    'age': [30],  # Example: Age of the person
    'gender': [1],  # Example: 1 for male, 0 for female
    'bmi': [23],  # Example: BMI value
    'who_bmi': ['Normal'],  # Example: WHO BMI category
    'phq_score': [12],  # Example: PHQ score
    'depression_severity': [2],  # Example: Depression severity level
    'depressiveness': [3],  # Example: Level of depressiveness
    'suicidal': [1],  # Example: 1 for suicidal thoughts, 0 for no suicidal thoughts
    'depression_treatment': [1],  # Example: 1 for treatment, 0 for no treatment
    'gad_score': [10],  # Example: GAD score
    'anxiety_severity': [3],  # Example: Anxiety severity level
    'anxiousness': [4],  # Example: Level of anxiousness
    'anxiety_diagnosis': [1],  # Example: 1 for diagnosed, 0 for not diagnosed
    'anxiety_treatment': [1],  # Example: 1 for treatment, 0 for no treatment
    'epworth_score': [9],  # Example: Epworth score
    'sleepiness': [3],  # Example: Sleepiness level
})

# Ensure the new data has the columns in the correct order, as the model expects
new_data = new_data[feature_order]

# Make the prediction using the trained Random Forest model
prediction = rf_model.predict(new_data)

# Output the prediction result
print(f"Predicted mental health diagnosis: {prediction[0]}")

import pandas as pd
import joblib
from sklearn.preprocessing import LabelEncoder

# Load the trained Random Forest model
rf_model = joblib.load('rf_model.pkl')

# Define the exact feature order used during training
feature_order = [
    'school_year', 'age', 'gender', 'bmi', 'who_bmi', 'phq_score',
    'depression_severity', 'depressiveness', 'suicidal', 'depression_treatment',
    'gad_score', 'anxiety_severity', 'anxiousness', 'anxiety_diagnosis',
    'anxiety_treatment', 'epworth_score', 'sleepiness'
]

# Example of new symptom data (ensure the data has the same features in the same order)
new_data = pd.DataFrame({
    'school_year': [2],  # Example: Year in school
    'age': [30],  # Example: Age of the person
    'gender': [1],  # Example: 1 for male, 0 for female
    'bmi': [23],  # Example: BMI value
    'who_bmi': ['Normal'],  # Example: WHO BMI category (categorical)
    'phq_score': [12],  # Example: PHQ score
    'depression_severity': [2],  # Example: Depression severity level
    'depressiveness': [3],  # Example: Level of depressiveness
    'suicidal': [1],  # Example: 1 for suicidal thoughts, 0 for no suicidal thoughts
    'depression_treatment': [1],  # Example: 1 for treatment, 0 for no treatment
    'gad_score': [10],  # Example: GAD score
    'anxiety_severity': [3],  # Example: Anxiety severity level
    'anxiousness': [4],  # Example: Level of anxiousness
    'anxiety_diagnosis': [1],  # Example: 1 for diagnosed, 0 for not diagnosed
    'anxiety_treatment': [1],  # Example: 1 for treatment, 0 for no treatment
    'epworth_score': [9],  # Example: Epworth score
    'sleepiness': [3],  # Example: Sleepiness level
})

# Initialize label encoder for 'who_bmi'
label_encoder = LabelEncoder()

# Fit and transform 'who_bmi' column to convert categorical string to numeric values
new_data['who_bmi'] = label_encoder.fit_transform(new_data['who_bmi'])

# Ensure the new data has the columns in the correct order, as the model expects
new_data = new_data[feature_order]

# Make the prediction using the trained Random Forest model
prediction = rf_model.predict(new_data)

# Output the prediction result
print(f"Predicted mental health diagnosis: {prediction[0]}")

import pandas as pd
import joblib
from sklearn.preprocessing import LabelEncoder

# Load the trained Random Forest model
rf_model = joblib.load('xgb_model.pkl')

# Define the exact feature order used during training
feature_order = [
    'school_year', 'age', 'gender', 'bmi', 'who_bmi', 'phq_score',
    'depression_severity', 'depressiveness', 'suicidal', 'depression_treatment',
    'gad_score', 'anxiety_severity', 'anxiousness', 'anxiety_diagnosis',
    'anxiety_treatment', 'epworth_score', 'sleepiness'
]

# Example of new symptom data (ensure the data has the same features in the same order)
new_data = pd.DataFrame({
    'school_year': [2],  # Example: Year in school
    'age': [30],  # Example: Age of the person
    'gender': [1],  # Example: 1 for male, 0 for female
    'bmi': [23],  # Example: BMI value
    'who_bmi': ['Normal'],  # Example: WHO BMI category (categorical)
    'phq_score': [12],  # Example: PHQ score
    'depression_severity': [2],  # Example: Depression severity level
    'depressiveness': [3],  # Example: Level of depressiveness
    'suicidal': [1],  # Example: 1 for suicidal thoughts, 0 for no suicidal thoughts
    'depression_treatment': [1],  # Example: 1 for treatment, 0 for no treatment
    'gad_score': [10],  # Example: GAD score
    'anxiety_severity': [3],  # Example: Anxiety severity level
    'anxiousness': [4],  # Example: Level of anxiousness
    'anxiety_diagnosis': [1],  # Example: 1 for diagnosed, 0 for not diagnosed
    'anxiety_treatment': [1],  # Example: 1 for treatment, 0 for no treatment
    'epworth_score': [9],  # Example: Epworth score
    'sleepiness': [3],  # Example: Sleepiness level
})

# Initialize label encoder for 'who_bmi'
label_encoder = LabelEncoder()

# Fit and transform 'who_bmi' column to convert categorical string to numeric values
new_data['who_bmi'] = label_encoder.fit_transform(new_data['who_bmi'])

# Ensure the new data has the columns in the correct order, as the model expects
new_data = new_data[feature_order]

# Make the prediction using the trained Random Forest model
prediction = rf_model.predict(new_data)

# Output the prediction result
print(f"Predicted mental health diagnosis: {prediction[0]}")

pip install transformers

from transformers import GPT2LMHeadModel, GPT2Tokenizer
import torch

# Load GPT-2 model and tokenizer
model_name = "gpt2"  # Use "gpt2" or any available variant on Hugging Face
model = GPT2LMHeadModel.from_pretrained(model_name)
tokenizer = GPT2Tokenizer.from_pretrained(model_name)

# Ensure the model is in evaluation mode
model.eval()

def generate_explanation(diagnosis):
    """
    Generates a natural language explanation and coping mechanisms based on the diagnosis.
    :param diagnosis: The predicted mental health condition (string)
    :return: A natural language explanation (string)
    """
    prompt = f"Explain the mental health condition '{diagnosis}' and suggest coping mechanisms and next steps."

    # Tokenize the input prompt and generate the output
    inputs = tokenizer.encode(prompt, return_tensors='pt')

    # Generate output
    with torch.no_grad():
        output = model.generate(inputs, max_length=200, num_return_sequences=1, no_repeat_ngram_size=2, temperature=0.7)

    # Decode the output tokens and return the result
    explanation = tokenizer.decode(output[0], skip_special_tokens=True)

    return explanation

# Example usage:
diagnosis = "Depression"  # This could be the model's predicted class
explanation = generate_explanation(diagnosis)

print("Explanation and Coping Mechanisms:")
print(explanation)

from transformers import GPT2LMHeadModel, GPT2Tokenizer
import torch

# Load GPT-2 model and tokenizer
model_name = "gpt2"  # Use "gpt2" or any available variant on Hugging Face
model = GPT2LMHeadModel.from_pretrained(model_name)
tokenizer = GPT2Tokenizer.from_pretrained(model_name)

# Ensure the model is in evaluation mode
model.eval()

def generate_explanation(diagnosis):
    """
    Generates a natural language explanation and coping mechanisms based on the diagnosis.
    :param diagnosis: The predicted mental health condition (string)
    :return: A natural language explanation (string)
    """
    prompt = f"Explain the mental health condition '{diagnosis}' and suggest coping mechanisms, next steps, and helpful resources."

    # Tokenize the input prompt and generate the output
    inputs = tokenizer.encode(prompt, return_tensors='pt')

    # Generate output
    with torch.no_grad():
        output = model.generate(
            inputs,
            max_length=200,
            num_return_sequences=1,
            no_repeat_ngram_size=2,
            temperature=0.8,  # More creativity in response
            do_sample=True,  # Enable sampling to allow variability in response
            pad_token_id=tokenizer.eos_token_id  # Ensure padding is handled correctly
        )

    # Decode the output tokens and return the result
    explanation = tokenizer.decode(output[0], skip_special_tokens=True)

    return explanation

# Example usage:
diagnosis = "Depression"  # This could be the model's predicted class
explanation = generate_explanation(diagnosis)

print("Explanation and Coping Mechanisms:")
print(explanation)

from transformers import GPT2LMHeadModel, GPT2Tokenizer
import torch

# Load GPT-2 model and tokenizer
model_name = "gpt2"  # Use "gpt2" or any available variant on Hugging Face
model = GPT2LMHeadModel.from_pretrained(model_name)
tokenizer = GPT2Tokenizer.from_pretrained(model_name)

# Ensure the model is in evaluation mode
model.eval()

def generate_explanation(diagnosis):
    """
    Generates a natural language explanation and coping mechanisms based on the diagnosis.
    :param diagnosis: The predicted mental health condition (string)
    :return: A natural language explanation (string)
    """
    prompt = f"Please explain the mental health condition '{diagnosis}' in simple terms, suggest practical coping mechanisms, and provide next steps that someone could take. Be empathetic, and include helpful resources for someone dealing with this condition."

    # Tokenize the input prompt and generate the output
    inputs = tokenizer.encode(prompt, return_tensors='pt')

    # Generate output
    with torch.no_grad():
        output = model.generate(
            inputs,
            max_length=200,
            num_return_sequences=1,
            no_repeat_ngram_size=2,
            temperature=0.8,  # More creativity in response
            do_sample=True,  # Enable sampling to allow variability in response
            pad_token_id=tokenizer.eos_token_id  # Ensure padding is handled correctly
        )

    # Decode the output tokens and return the result
    explanation = tokenizer.decode(output[0], skip_special_tokens=True)

    return explanation

# Example usage:
diagnosis = "Depression"  # This could be the model's predicted class
explanation = generate_explanation(diagnosis)

print("Explanation and Coping Mechanisms:")
print(explanation)

import torch
from transformers import GPT2LMHeadModel, GPT2Tokenizer

# Load the GPT-2 model and tokenizer
model_name = "gpt2"  # You can also use a fine-tuned GPT-2 model if available
tokenizer = GPT2Tokenizer.from_pretrained(model_name)
model = GPT2LMHeadModel.from_pretrained(model_name)

# Ensure pad_token_id is set to avoid warnings
tokenizer.pad_token = tokenizer.eos_token

def generate_explanation(diagnosis):
    # Prepare the input text for explanation generation
    input_text = f"Explain the mental health condition: {diagnosis}. Provide coping mechanisms and next steps."

    # Tokenize the input text
    input_ids = tokenizer.encode(input_text, return_tensors="pt", truncation=True, max_length=128)

    # Generate the explanation
    with torch.no_grad():
        output = model.generate(input_ids, max_length=256, num_beams=5, no_repeat_ngram_size=2, temperature=0.7)

    # Decode the generated explanation and return it
    explanation = tokenizer.decode(output[0], skip_special_tokens=True)
    return explanation

def predict_condition(symptoms):
    # A basic mapping of symptoms to conditions
    if "sad" in symptoms or "hopeless" in symptoms:
        diagnosis = "Depression"
    elif "worry" in symptoms or "fear" in symptoms:
        diagnosis = "Anxiety"
    else:
        diagnosis = "Unknown"

    return diagnosis

def main():
    # Input symptoms
    symptoms = input("Enter symptoms (e.g., sadness, hopelessness, worry, etc.): ")

    # Predict the condition based on symptoms
    diagnosis = predict_condition(symptoms)
    print(f"Predicted Condition: {diagnosis}")

    # Generate an explanation for the condition
    explanation = generate_explanation(diagnosis)
    print(f"Explanation and Coping Mechanisms:\n{explanation}")

if __name__ == "__main__":
    main()

import torch
from transformers import GPT2LMHeadModel, GPT2Tokenizer

# Load the pre-trained GPT-2 model and tokenizer
model_name = "gpt2"  # You can also use other models such as 'gpt2-medium' or 'gpt2-large'
model = GPT2LMHeadModel.from_pretrained(model_name)
tokenizer = GPT2Tokenizer.from_pretrained(model_name)

# Set the model to evaluation mode
model.eval()

def predict_mental_health(symptoms):
    """
    Predict the mental health condition based on the symptoms provided.
    For simplicity, we will map common symptoms to conditions here.
    """
    # Here you could implement more complex prediction logic or use a different model
    # For this example, we'll assume worry maps to anxiety, sadness to depression, etc.
    if "worry" in symptoms:
        return "Anxiety"
    elif "sadness" in symptoms or "hopelessness" in symptoms:
        return "Depression"
    elif "fatigue" in symptoms:
        return "Fatigue-related disorders"
    else:
        return "Unspecified condition"

def generate_explanation(diagnosis):
    """
    Generate a natural language explanation for the predicted mental health condition.
    """
    # Refined prompt to guide the model better
    input_text = f"Please provide a detailed explanation for the mental health condition '{diagnosis}', including common causes, symptoms, and recommended coping mechanisms."

    input_ids = tokenizer.encode(input_text, return_tensors="pt", truncation=True, max_length=128)

    with torch.no_grad():
        output = model.generate(input_ids, max_length=256, num_beams=5, no_repeat_ngram_size=2, temperature=0.7)

    explanation = tokenizer.decode(output[0], skip_special_tokens=True)

    # Post-process output to clean and improve relevance
    if "Copyright" in explanation:  # Example of unwanted output to remove
        explanation = "Sorry, I couldn't generate a valid explanation. Please try again."

    return explanation

# Command-line interface to interact with the model
def main():
    # User input for symptoms
    symptoms = input("Enter symptoms (e.g., sadness, hopelessness, worry, etc.): ").lower()

    # Step 1: Predict mental health condition based on symptoms
    predicted_condition = predict_mental_health(symptoms)
    print(f"Predicted Condition: {predicted_condition}")

    # Step 2: Generate explanation and coping mechanisms
    explanation = generate_explanation(predicted_condition)
    print(f"Explanation and Coping Mechanisms: {explanation}")

if __name__ == "__main__":
    main()

import torch
from transformers import GPT2LMHeadModel, GPT2Tokenizer

# Load the pre-trained GPT-2 model and tokenizer
model_name = "gpt2"  # You can also use other models such as 'gpt2-medium' or 'gpt2-large'
model = GPT2LMHeadModel.from_pretrained(model_name)
tokenizer = GPT2Tokenizer.from_pretrained(model_name)

# Ensure the model is in evaluation mode
model.eval()

def predict_mental_health(symptoms):
    """
    Predict the mental health condition based on the symptoms provided.
    For simplicity, we will map common symptoms to conditions here.
    """
    # Here you could implement more complex prediction logic or use a different model
    # For this example, we'll assume worry maps to anxiety, sadness to depression, etc.
    if "worry" in symptoms:
        return "Anxiety"
    elif "sadness" in symptoms or "hopelessness" in symptoms:
        return "Depression"
    elif "fatigue" in symptoms:
        return "Fatigue-related disorders"
    else:
        return "Unspecified condition"

def generate_explanation(diagnosis):
    """
    Generates a natural language explanation and coping mechanisms based on the diagnosis.
    :param diagnosis: The predicted mental health condition (string)
    :return: A natural language explanation (string)
    """
    prompt = f"Please explain the mental health condition '{diagnosis}' in simple terms, suggest practical coping mechanisms, and provide next steps that someone could take. Be empathetic, and include helpful resources for someone dealing with this condition."

    # Tokenize the input prompt and generate the output
    inputs = tokenizer.encode(prompt, return_tensors='pt')

    # Generate output
    with torch.no_grad():
        output = model.generate(
            inputs,
            max_length=200,
            num_return_sequences=1,
            no_repeat_ngram_size=2,
            temperature=0.8,  # More creativity in response
            do_sample=True,  # Enable sampling to allow variability in response
            pad_token_id=tokenizer.eos_token_id  # Ensure padding is handled correctly
        )

    # Decode the output tokens and return the result
    explanation = tokenizer.decode(output[0], skip_special_tokens=True)

    return explanation

# Command-line interface to interact with the model
def main():
    # User input for symptoms
    symptoms = input("Enter symptoms (e.g., sadness, hopelessness, worry, etc.): ").lower()

    # Step 1: Predict mental health condition based on symptoms
    predicted_condition = predict_mental_health(symptoms)
    print(f"Predicted Condition: {predicted_condition}")

    # Step 2: Generate explanation and coping mechanisms
    explanation = generate_explanation(predicted_condition)
    print(f"Explanation and Coping Mechanisms: {explanation}")

if __name__ == "__main__":
    main()

from transformers import AutoTokenizer, AutoModelForCausalLM

model_name = "mistralai/Mistral-7B-Instruct-v0.1"  # Use Hugging Face model
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name, device_map="auto")

def generate_explanation(diagnosis):
    """
    Generates an explanation using Mistral-7B.
    """
    prompt = f"Explain the mental health condition '{diagnosis}' and suggest coping mechanisms."

    # Tokenize input
    inputs = tokenizer(prompt, return_tensors="pt").to("cuda")

    # Generate response
    output = model.generate(**inputs, max_length=200)

    # Decode response
    return tokenizer.decode(output[0], skip_special_tokens=True)

# Example usage
diagnosis = "Depression"
explanation = generate_explanation(diagnosis)

print("Explanation and Coping Mechanisms:")
print(explanation)

from transformers import AutoTokenizer, AutoModelForCausalLM

# Authenticate Hugging Face
from huggingface_hub import login
login(token="...............")  # Replace with your actual token

# Load model and tokenizer
model_name = "mistralai/Mistral-7B-Instruct-v0.1"
tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True)
model = AutoModelForCausalLM.from_pretrained(model_name, device_map="auto", use_auth_token=True)

pip install transformers torch accelerate huggingface_hub

from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Load Mistral-7B model and tokenizer (base model, not instruction-tuned)
model_name = "mistralai/Mistral-7B-Instruct-v0.2"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map="auto")

# Ensure the model is in evaluation mode
model.eval()

def generate_explanation(diagnosis):
    """
    Generates a natural language explanation and coping mechanisms for a given mental health condition.
    :param diagnosis: The predicted mental health condition (string)
    :return: A natural language explanation (string)
    """
    prompt = (f"You are an expert psychiatrist. Explain the mental health condition '{diagnosis}' "
              "in simple terms and suggest coping mechanisms, treatment options, and resources.")

    # Tokenize the input prompt
    inputs = tokenizer(prompt, return_tensors="pt").to("cuda")

    # Generate response
    with torch.no_grad():
        output = model.generate(
            **inputs,
            max_length=300,
            temperature=0.7,  # Adjust for randomness
            top_k=50,  # Sampling strategy
            top_p=0.9,  # Sampling strategy
            repetition_penalty=1.2,
            pad_token_id=tokenizer.eos_token_id
        )

    # Decode the generated text
    explanation = tokenizer.decode(output[0], skip_special_tokens=True)
    return explanation

# Example usage:
diagnosis = "Depression"
explanation = generate_explanation(diagnosis)

print("\nExplanation and Coping Mechanisms:")
print(explanation)

from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Public Falcon-7B model (no gating)
model_name = "tiiuae/falcon-7b"

# Load tokenizer and model
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map="auto")

# Ensure model is in evaluation mode
model.eval()

def generate_explanation(diagnosis):
    """
    Generates a natural language explanation and coping mechanisms for a given mental health condition.
    """
    prompt = (f"You are a professional mental health expert. Explain the condition '{diagnosis}' "
              "in simple terms and suggest coping strategies.")

    # Tokenize input
    inputs = tokenizer(prompt, return_tensors="pt").to("cuda")

    # Generate response
    with torch.no_grad():
        output = model.generate(
            **inputs,
            max_length=300,
            temperature=0.7,
            top_k=50,
            top_p=0.9,
            repetition_penalty=1.2,
            pad_token_id=tokenizer.eos_token_id
        )

    # Decode the generated text
    explanation = tokenizer.decode(output[0], skip_special_tokens=True)
    return explanation

# Example usage:
diagnosis = "Generalized Anxiety Disorder"
explanation = generate_explanation(diagnosis)

print("\nExplanation and Coping Mechanisms:")
print(explanation)

pip install transformers peft accelerate bitsandbytes datasets

from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments
from peft import LoraConfig, get_peft_model, TaskType
import torch

# Load Falcon-7B (public & non-gated)
model_name = "tiiuae/falcon-7b"

# Load tokenizer
tokenizer = AutoTokenizer.from_pretrained(model_name)

# Load model with quantization (4-bit QLoRA)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16,
    load_in_4bit=True,   # QLoRA: Load in 4-bit precision
    device_map="auto"
)

# LoRA configuration (for parameter-efficient tuning)
lora_config = LoraConfig(
    r=16,                    # Rank: Controls adaptation flexibility
    lora_alpha=32,           # Scaling factor
    lora_dropout=0.1,        # Dropout to prevent overfitting
    bias="none",
    task_type=TaskType.CAUSAL_LM
)

# Wrap Falcon-7B with LoRA
model = get_peft_model(model, lora_config)
model.print_trainable_parameters()  # Check trainable parameters

pip install -U bitsandbytes

pip install -U bitsandbytes transformers accelerate

import bitsandbytes
print(bitsandbytes.__version__)  # Should print the installed version

!pip install --upgrade bitsandbytes
!pip install --upgrade accelerate
!pip install --upgrade transformers
!pip install --upgrade torch

from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

model_name = "tiiuae/falcon-7b-instruct"

# Load tokenizer
tokenizer = AutoTokenizer.from_pretrained(model_name)

# Load model in 4-bit quantization mode
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    load_in_4bit=True,  # Enables 4-bit quantization
    torch_dtype=torch.float16,
    device_map="auto"  # Auto-distribute model across available GPUs
)

# Generate text
def generate_explanation(diagnosis):
    prompt = f"Explain the mental health condition '{diagnosis}' and suggest coping mechanisms and potential next steps."

    inputs = tokenizer(prompt, return_tensors="pt").to("cuda")  # Move input to GPU
    with torch.no_grad():
        output = model.generate(inputs.input_ids, max_length=200, temperature=0.7)

    return tokenizer.decode(output[0], skip_special_tokens=True)

# Example usage
print(generate_explanation("Anxiety"))

